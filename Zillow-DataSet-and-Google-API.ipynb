{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python Standard Library\n",
    "import time\n",
    "\n",
    "#Python Packaging Index\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy import GoogleV3\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the link below is outdated or not working you can download the csv from https://www.zillow.com/research/data/ using Data Type: ZHVI Single-Family Homes Time Series and Geography: Neighborhood.\n",
    "\n",
    "df = pd.read_csv(\"https://files.zillowstatic.com/research/public_v2/zhvi/Neighborhood_zhvi_uc_sfr_sm_sa_mon.csv?t=1617841871\")\n",
    "df.insert(loc = 9, \n",
    "          column = 'Lon', \n",
    "          value = 0.0)\n",
    "df.insert(loc = 9, \n",
    "          column = 'Lat', \n",
    "          value = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting dataframe by RegionID, to bring some sort of order to the dataset\n",
    "df = df.sort_values(by=['RegionID'], inplace=False)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#In the Event of a power failure, or Internet failure, sectioning off data into rows of 1000 and saving them to an .csv file\n",
    "ranges = [x for x in range(0,df.shape[0],1000)]\n",
    "ranges.append(df.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Calls the Google Maps API through the geopy python pacakge and searches for location with the given RegionName, City, and State. Here RegionName's are synonomous with neighborhood names. Given that location, google maps api give us the latitude and longitude. \n",
    "\n",
    "# Even with 137 mbps connection, I was only able to get about 1.5 iterations/second. There was seemingly a rate limitation on api requests. This brings the total queue to about 3 hours to fulfill.\n",
    "\n",
    "# According to google cloud pricing for geocoding ( https://cloud.google.com/maps-platform/pricing/ : Places->Geocoding) there is a $5 per 1000 requests pricing option. Google is generous in that upon signing up they give you $300 in credits, and then for each month after you get $200 worth of credits free. With 16096 locations to be queried, that would bring us to $80.48 for this series of quieries, about 27% of our $300 budget.\n",
    "\n",
    "# Once you sign up gor google cloud google maps platform with $300 free credits, you will be given an API_KEY, place it below.\n",
    "API_KEY = \"\"\n",
    "\n",
    "start = 0\n",
    "for n in range(start, len(ranges)):\n",
    "    if n == 0:\n",
    "        pass\n",
    "    else:\n",
    "        start = ranges[n-1]\n",
    "        end = ranges[n]\n",
    "\n",
    "        page = n  #MUST CHANGE WITH EACH ITERATION\n",
    "\n",
    "        for i in tqdm(range(start,end)):\n",
    "            row = df.loc[i]\n",
    "            place = '{}, {}, {}, USA'.format(row['RegionName'], row['City'],row['State'])\n",
    "            try:\n",
    "                location = GoogleV3(api_key=API_KEY).geocode(place)\n",
    "                df.at[i,'Lat'] = location.latitude\n",
    "                df.at[i,'Lon'] = location.longitude\n",
    "            except:\n",
    "                df.at[i,'Lat'] = np.nan\n",
    "                df.at[i,'Lon'] = np.nan\n",
    "\n",
    "        part = df.loc[start:end-1]\n",
    "        part.to_csv('zillow-dataset-lat-long-part{}.csv'.format(page), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There will be 3 cleaning phases:\n",
    "# 1. Dealing with No Lat Lon Found\n",
    "# 2. Dealing with almost Duplicates\n",
    "# 3. Dealing with Visual Anomolies\n",
    "\n",
    "# Cleaning Phase 1: Should end up with around 50 not named. These will have to be manually entered. Not bad for 60/16096.\n",
    "\n",
    "df[df['Lat'].isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "      State                    Metro          RegionName  Counts\n594      AZ  Phoenix-Mesa-Scottsdale             Encanto       2\n811      AZ  Phoenix-Mesa-Scottsdale          Pepperwood       2\n833      AZ  Phoenix-Mesa-Scottsdale           Ray Ranch       2\n946      AZ  Phoenix-Mesa-Scottsdale  Superstition Ranch       2\n1196     CA              Bakersfield            Downtown       2\n...     ...                      ...                 ...     ...\n15281    WA  Seattle-Tacoma-Bellevue             Madrona       2\n15347    WA  Seattle-Tacoma-Bellevue            Overlake       2\n15357    WA  Seattle-Tacoma-Bellevue           Pinehurst       2\n15370    WA  Seattle-Tacoma-Bellevue             Redondo       2\n15379    WA  Seattle-Tacoma-Bellevue           Riverview       2\n\n[106 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>Metro</th>\n      <th>RegionName</th>\n      <th>Counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>594</th>\n      <td>AZ</td>\n      <td>Phoenix-Mesa-Scottsdale</td>\n      <td>Encanto</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>811</th>\n      <td>AZ</td>\n      <td>Phoenix-Mesa-Scottsdale</td>\n      <td>Pepperwood</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>833</th>\n      <td>AZ</td>\n      <td>Phoenix-Mesa-Scottsdale</td>\n      <td>Ray Ranch</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>946</th>\n      <td>AZ</td>\n      <td>Phoenix-Mesa-Scottsdale</td>\n      <td>Superstition Ranch</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>CA</td>\n      <td>Bakersfield</td>\n      <td>Downtown</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15281</th>\n      <td>WA</td>\n      <td>Seattle-Tacoma-Bellevue</td>\n      <td>Madrona</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15347</th>\n      <td>WA</td>\n      <td>Seattle-Tacoma-Bellevue</td>\n      <td>Overlake</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15357</th>\n      <td>WA</td>\n      <td>Seattle-Tacoma-Bellevue</td>\n      <td>Pinehurst</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15370</th>\n      <td>WA</td>\n      <td>Seattle-Tacoma-Bellevue</td>\n      <td>Redondo</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15379</th>\n      <td>WA</td>\n      <td>Seattle-Tacoma-Bellevue</td>\n      <td>Riverview</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>106 rows Ã— 4 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Cleaning Phase 2: because queries were searched by RegionName, City, and State. There could be duplicates that exist like:\n",
    "# A. Murray Hill Neighborhood NY NY New York Newyork-Newark-Jersey City Nassau County\n",
    "# B. Murray Hill Neighborhood NY NY New York Newyork-Newark-Jersey City New York County\n",
    "\n",
    "# Where A. and B. are not duplicates as they have different county names (Nassau County & New York County). But since because we queried google based upon City, rather than County they might have the same Latitude and Longitude. \n",
    "\n",
    "# to find these Duplicates, switch group_type's group element. There should be around 150. \n",
    "group = ['City', 'Metro', 'CountyName']\n",
    "group_type = group[0]\n",
    "q = df[[\"State\",group_type, \"RegionName\"]].value_counts(sort=False).reset_index()\n",
    "q.columns = [\"State\",group_type, \"RegionName\", 'Counts']\n",
    "display(q[q['Counts']>1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Once visualized, you can continue to phase 3 of cleaning.\n",
    "#  Cleaning Phase 3: go to each city and metro and look for outliers"
   ]
  }
 ]
}